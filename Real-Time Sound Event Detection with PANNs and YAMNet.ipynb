{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This notebook demonstrates how to use pre-trained models (PANNs and YAMNet) for real-time inference. PANNs and YAMNet both gives probabilities over AudioSet categories.\n",
    "These models are currently used independently. Their predictions are not yet combined."
   ],
   "id": "270b8679780085f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Session Lifecycle\n",
    "   - `start_session()` opens the JSONL file, timestamps the start, and resets counters\n",
    "   - `process_chunk(wave_chunk, chunk_sr)` is called for each arriving audio frame\n",
    "   - `stop_session()` closes files and writes a compact session summary (start/stop time, number of frames, config)"
   ],
   "id": "318fffae3a245a41"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " Inference Pipeline",
   "id": "5acee4184b4cf7a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from realtime_solo import RealTimeSolo\n",
    "import librosa\n",
    "import numpy as np\n",
    "# Step 1: Initialize\n",
    "solo = RealTimeSolo(\"config.yaml\")\n",
    "solo.start_session()\n",
    "waveform, sr = librosa.load(\"resources_R9_ZSCveAHg_7s.wav\", sr=16000)"
   ],
   "id": "48072ef94263e3d",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint path: C:\\Users\\asus/panns_data/Cnn14_DecisionLevelMax.pth\n",
      "GPU number: 1\n",
      "results saved in ./run\n"
     ]
    }
   ],
   "execution_count": 2,
   "source": [
    "\n",
    "# Step 2: Frame-wise chunking and detection\n",
    "frame_size = int(solo.sr * solo.chunk_ms / 1000.0)\n",
    "for offset in range(0, len(waveform), frame_size):\n",
    "    chunk = waveform[offset : offset + frame_size]\n",
    "    if len(chunk) < frame_size:\n",
    "        chunk = np.pad(chunk, (0, frame_size - len(chunk)))\n",
    "    solo.process_chunk(chunk, chunk_sr=16000)\n",
    "\n",
    "solo.stop_session()\n",
    "print('results saved in ./runs')"
   ],
   "id": "43a80bde94d09482"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Output Files\n",
    "stream_preds.jsonl: frame-wise detection results (1 line per chunk)\n",
    "stream_summary.json: metadata like timestamps, chunk count"
   ],
   "id": "e072abecbdd0b9a9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The core detection logic:",
   "id": "5333cfd44ae767bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "local_window = append_chunk_to_window(chunk)\n",
    "pann_output = pann_model.infer_clipwise(local_window)\n",
    "yam_output  = yamnet_model.infer_clipwise(local_window)\n",
    "row = {\n",
    "    \"time_start\": ..., \"time_end\": ...,\n",
    "    \"PANN\":   {\"top_label\": ..., \"top_score\": ...},\n",
    "    \"YAMNet\": {\"top_label\": ..., \"top_score\": ...}\n",
    "}\n"
   ],
   "id": "1b5c7529bc212f96"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Real-Time Integration with Recorder\n",
    "Inside record_sound.py:\n",
    "Tkinter GUI starts and stops recording\n",
    "Audio chunks are continuously streamed to the detection system"
   ],
   "id": "61b0d0b279678a86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "rec = ChunkRecorder(sr=16000, chunk_seconds=2, on_chunk=handle_chunk)\n",
    "rec.start()\n",
    "\n",
    "def handle_chunk(chunk):\n",
    "    solo.process_chunk(chunk, chunk_sr=16000)  # Real-time inference per chunk"
   ],
   "id": "8a7425dc5a00bf03"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
